from google import genai

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings


# =========================
# ðŸ”‘ CREATE GEMINI CLIENT
# =========================
client = genai.Client(api_key="AIzaSyA-KOVK79fgmtSDjV3DIc1CfIyLQjf1CoQ")


# =========================
# ðŸ”¹ EMBEDDING FUNCTION
# =========================
def get_embedding(text):
    response = client.models.embed_content(
        model="gemini-embedding-001",
        contents=text
    )
    return response.embeddings[0].values


# =========================
# ðŸ”¹ CUSTOM EMBEDDING CLASS
# =========================
class GeminiEmbeddings(Embeddings):
    def embed_documents(self, texts):
        return [get_embedding(t) for t in texts]

    def embed_query(self, text):
        return get_embedding(text)


# =========================
# ðŸ”¹ LOAD PDF
# =========================
loader = PyPDFLoader("data.pdf")
docs = loader.load()


# =========================
# ðŸ”¹ SPLIT INTO CHUNKS
# =========================
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100
)

chunks = splitter.split_documents(docs)


# =========================
# ðŸ”¹ CREATE VECTOR DB
# =========================
embeddings = GeminiEmbeddings()
db = FAISS.from_documents(chunks, embeddings)


# =========================
# ðŸ”¹ USER QUERY
# =========================
query = input("\nAsk a question: ")


# =========================
# ðŸ”¹ SEARCH
# =========================
results = db.similarity_search(query, k=3)

context = "\n\n".join([r.page_content for r in results])


# =========================
# ðŸ”¹ PROMPT
# =========================
prompt = f"""
You are analyzing documents.

Rules:
- Only answer using the context
- If not found, say "Not found in document"
- Do NOT assume anything
- Say "mentioned in document"

Context:
{context}

Question:
{query}
"""


# =========================
# ðŸ”¹ GENERATE ANSWER
# =========================
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=prompt
)


# =========================
# ðŸ”¹ PRINT
# =========================
print("\nAnswer:\n")
print(response.text)


# =========================
# ðŸ”¹ SOURCES
# =========================
print("\nSources:\n")

for i, r in enumerate(results):
    print(f"Source {i+1} (Page {r.metadata.get('page', 'N/A')}):")
    print(r.page_content[:300])
    print("-----\n")
